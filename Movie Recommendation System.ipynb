{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9acc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7219f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5f487",
   "metadata": {},
   "source": [
    "# Load The Data Set Movies & Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ab6680",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmdb_5000_movies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmdb_5000_movies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m credits \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmdb_5000_credits.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anacondainstallation\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\Anacondainstallation\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Anacondainstallation\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32md:\\Anacondainstallation\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Anacondainstallation\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmdb_5000_movies.csv'"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "credits = pd.read_csv(\"tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3e3fd",
   "metadata": {},
   "source": [
    "# Explore The Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75199e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45eaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196db8f3",
   "metadata": {},
   "source": [
    "As wee see in the movies dataset there is all the important information about movies like when movies release and in which language also about generes and budgets of the movies so we will keep some of these columns and skip some columns that we dont need.\n",
    "\n",
    ".................\n",
    "\n",
    "Similarly, in the credits dataset we have movies_id and information about cast of the movie and crew (all the other members in the movie) So, we have to datasets in the first step we need to be merged them so that we cxan easily handle only one dataframe for project, in the below stpe we will merge these two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e842476",
   "metadata": {},
   "source": [
    "# We are merging these two datasets on the basis of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87219ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b35ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape\n",
    "\n",
    "#Now after merging the datasets we have 23 columns and 4809 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697c745",
   "metadata": {},
   "source": [
    "It seems that after merging the dataset we will have 24 columns, but we find it 23 This is because we meerged it on the basis odf title so it is not in the counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9047ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bd59b",
   "metadata": {},
   "source": [
    "# Now lets Find out the columns that we need to be used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdbe466",
   "metadata": {},
   "source": [
    "As we know we have to make a content based recommendation system so we are trying to create tags.\n",
    "\n",
    "here's the columns that are important and we will consider for our project\n",
    "\n",
    "1. genres\n",
    "2. movie_id\n",
    "3. keywords\n",
    "4. title\n",
    "5. overview\n",
    "6. cast (based on character like Salman khan etc)\n",
    "7. crew (director etc)\n",
    "\n",
    "now we will extract these columns for further proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[[\"movie_id\",\"title\",\"overview\",\"genres\",\"keywords\", \"cast\",\"crew\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032df158",
   "metadata": {},
   "source": [
    "now we will create a new column TAGS, and we will combine overivew, generes, keywords, cast and crew to get tags column in this way we will have 3 columns \n",
    "\n",
    "1. movie_id\n",
    "2. title\n",
    "3. tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294cd87",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71346c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "\n",
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e179050",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the duplicate data\n",
    "\n",
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek the genere columns for merging to get tag colum\n",
    "\n",
    "movies.iloc[0].genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561eb33",
   "metadata": {},
   "source": [
    "This is the list of dictionaries and our task is to get just this list \n",
    "\n",
    "[\"Action\",\"Adventure\",\"Fantasy\",\"Science Fiction\"]\n",
    "\n",
    "for this will make a function that will get this work done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def convert(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):        \n",
    "        L.append(i[\"name\"])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"genres\"].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0746c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f6f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dca034",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for keyword colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c59db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert3(obj):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            L.append(i['name'])\n",
    "            counter+=1\n",
    "        else:\n",
    "            break\n",
    "    return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"cast\"] = movies[\"cast\"].apply(convert3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7631afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ad33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_director(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(fetch_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"overview\"] = movies[\"overview\"].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861fce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the spaces in double words (one name) from these columns for avoiding conflit to get recomendation , becasue first names may be same for 2 persons \n",
    "\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies[\"keywords\"] = movies[\"keywords\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies[\"cast\"] = movies[\"cast\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies[\"crew\"] = movies[\"crew\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec85d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69433239",
   "metadata": {},
   "source": [
    "# Concatenate the above columns to get tag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57525d",
   "metadata": {},
   "source": [
    "As we acheived our task to make tag column now the other columns we will remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = movies[[\"movie_id\", \"title\", \"tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c528e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7edd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now convert the list of tags column(values) into string\n",
    "\n",
    "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"tags\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159afcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"tags\"] = new_df[\"tags\"].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b5bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e713e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43ed2825",
   "metadata": {},
   "source": [
    "# Now Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22528cc9",
   "metadata": {},
   "source": [
    "our task is to make a system that recommend the same type of movies based on tags, \n",
    "\n",
    "so our 1st task is to find out the similarity between the movies tags (paragraph) thats why we will use vectorization, we will apply technique bags of words on the tags columns so that we will have vector coresponding to each move and in this wahy we can get our target similar words for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21367e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db337b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9722c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5834b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movies_list = sorted(list(enumerate(distances)),reverse=True,key = lambda x: x[1])[1:6]\n",
    "    \n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].title)\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(\"Avatar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe72014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0acb311",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(new_df\u001b[38;5;241m.\u001b[39mto_dict(), \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_dict.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(new_df.to_dict(), open(\"movie_dict.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity, open(\"similarity.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e898d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
